{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jafarid/code/yogaposes/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jafarid/code/yogaposes'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path \n",
    "    resnet_trained_model_path: Path\n",
    "    resnet_updated_base_model_path: Path\n",
    "    traning_data: Path\n",
    "    params_augmentation: bool\n",
    "    params_image_size: list \n",
    "    params_batch_size: int \n",
    "    params_epoches: int\n",
    "    params_learning_rate: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yogaposes.constants import *\n",
    "from yogaposes.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class configurationManager:\n",
    "    def __init__(self,config_file_path=CONFIG_FILE_PATH, params_file_path=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_traning_config(self) -> TrainingConfig:\n",
    "        model_training = self.config.model_training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        training_data = os.path.join(self.config.data_ingestion.root_dir, 'yoga-poses-dataset')\n",
    "        \n",
    "        create_directories([model_training.root_dir])\n",
    "        \n",
    "        training_config = TrainingConfig(root_dir= model_training.resnet_trained_model_path, \n",
    "                                        resnet_trained_model_path= model_training.resnet_trained_model_path,\n",
    "                                        resnet_updated_base_model_path= prepare_base_model.resnet_updated_base_model_path,\n",
    "                                        traning_data = training_data,\n",
    "                                        params_augmentation = self.params.AUGMENTATION,\n",
    "                                        params_image_size = self.params.IMAGE_SIZE,\n",
    "                                        params_batch_size= self.params.BATCH_SIZE,\n",
    "                                        params_epoches = self.params.EPOCHS,\n",
    "                                        params_learning_rate = self.params.LEARNING_RATE\n",
    "                                        )\n",
    "        \n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, CenterCrop\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer(object):\n",
    "    def __init__(self, config:TrainingConfig, loss_fn=None, optimizer=None):\n",
    "        self.config = config\n",
    "        self.model = self.load_model()\n",
    "        self.loss_fn = loss_fn if loss_fn else nn.CrossEntropyLoss(reduction='mean')\n",
    "        self.optimizer = optimizer if optimizer else optim.adam(self.model.parameters(), lr=self.config.params_learning_rate)\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def load_model(self):\n",
    "        return torch.load(self.config.resnet_updated_base_model_path)\n",
    "    \n",
    "    def set_loaders(self):\n",
    "        # image net statistics\n",
    "        normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])\n",
    "        \n",
    "        composer = Compose([Resize(256), CenterCrop(224), ToTensor(), normalizer])\n",
    "        \n",
    "        train_data = ImageFolder(root=os.path.join(self.config.traning_data,'TRAIN'), transform=composer)\n",
    "        val_data = ImageFolder(root=os.path.join(self.config.traning_data,'TEST'), transform=composer)\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=self.config.params_batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=self.config.params_batch_size)\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yogaposes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
